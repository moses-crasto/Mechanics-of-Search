{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moses-crasto/Mechanics-of-Search/blob/main/MoS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NBhrGc81d0L"
      },
      "source": [
        "# **VSM O**/P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp_dlOkFwNB0",
        "outputId": "9d4f00cf-d94c-48d4-a592-e266b74e6bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to parse the XML file\n",
        "def parse_xml_file(xml_file):\n",
        "    docs = []\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for doc in root.findall('doc'):\n",
        "        doc_dict = {}\n",
        "        doc_dict['title'] = doc.find('title').text.strip().lower() if doc.find('title') is not None and doc.find('title').text is not None else ''\n",
        "        doc_dict['author'] = doc.find('author').text.strip().lower() if doc.find('author') is not None and doc.find('author').text is not None else ''\n",
        "        doc_dict['bib'] = doc.find('bib').text.strip().lower() if doc.find('bib') is not None and doc.find('bib').text is not None else ''\n",
        "        doc_dict['text'] = doc.find('text').text.strip().lower() if doc.find('text') is not None and doc.find('text').text is not None else ''\n",
        "        docs.append(doc_dict)\n",
        "    return docs\n",
        "\n",
        "# Load XML data into a DataFrame\n",
        "xml_file = '/content/cran.all.1400.xml'\n",
        "doc_elements = parse_xml_file(xml_file)\n",
        "df = pd.DataFrame(doc_elements)\n",
        "\n",
        "# Parse XML file to extract queries\n",
        "def parse_query_xml(xml_file):\n",
        "    queries = {}\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    queries_list = root.findall('top')\n",
        "\n",
        "    for index, query in enumerate(queries_list):\n",
        "        query_text = query.find('title').text.strip()\n",
        "        queries[index + 1] = query_text\n",
        "\n",
        "    return queries\n",
        "\n",
        "# Load queries\n",
        "queries = parse_query_xml('cran.qry.xml')\n",
        "\n",
        "# Tokenize, preprocess, stem, and remove stop words from the documents and queries\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(title, author, bib, text):\n",
        "    all_text = ' '.join([title, author, bib, text])\n",
        "    tokens = word_tokenize(all_text.lower())\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Preprocess documents\n",
        "df['preprocessed_text'] = df.apply(lambda row: preprocess_text(row['title'], row['author'], row['bib'], row['text']), axis=1)\n",
        "\n",
        "# Preprocess queries\n",
        "preprocessed_queries = {query_id: preprocess_text(query_text, '', '', '') for query_id, query_text in queries.items()}\n",
        "\n",
        "# TF-IDF vectorizer parameters for better performance\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, min_df=0.001, max_features=5000, ngram_range=(1, 2))\n",
        "\n",
        "# Fit TF-IDF vectorizer on preprocessed documents\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "output_file = \"vsm_output.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for query_id, query_text in preprocessed_queries.items():\n",
        "        # Transform the preprocessed query using the trained TF-IDF vectorizer\n",
        "        query_vector = tfidf_vectorizer.transform([query_text])\n",
        "\n",
        "        # Compute cosine similarity between the query vector and all document vectors\n",
        "        cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
        "\n",
        "        # Get the indices of documents sorted by similarity score\n",
        "        sorted_indices = cosine_similarities.argsort()[0][::-1]\n",
        "\n",
        "        # Write the top 100 results to the output file\n",
        "        for rank, idx in enumerate(sorted_indices[:100], start=1):\n",
        "            docno = idx + 1  # Since docno starts from 1\n",
        "            similarity = cosine_similarities[0][idx]\n",
        "            f.write(f\"{query_id} 0 {docno} {rank} {similarity} vsm\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDBw0oFR2YJ4"
      },
      "source": [
        "# **BM25** O/P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V40gEndU1pWj",
        "outputId": "1cbc4552-6370-4796-8d48-804bb644fdb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load XML data into a DataFrame\n",
        "xml_file = '/content/cran.all.1400.xml'\n",
        "tree = ET.parse(xml_file)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Preprocess documents\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "preprocessed_documents = []\n",
        "all_doc_tokens = []  # Store all document tokens for IDF calculation\n",
        "for doc in root.findall('doc'):\n",
        "    title = doc.find('title').text.strip().lower() if doc.find('title') is not None and doc.find('title').text is not None else ''\n",
        "    author = doc.find('author').text.strip().lower() if doc.find('author') is not None and doc.find('author').text is not None else ''\n",
        "    bib = doc.find('bib').text.strip().lower() if doc.find('bib') is not None and doc.find('bib').text is not None else ''\n",
        "    text = doc.find('text').text.strip().lower() if doc.find('text') is not None and doc.find('text').text is not None else ''\n",
        "\n",
        "    # Tokenize, stem, and remove stop words for title, author, bib, and text\n",
        "    title_tokens = [stemmer.stem(token) for token in word_tokenize(title) if token not in stop_words]\n",
        "    author_tokens = [stemmer.stem(token) for token in word_tokenize(author) if token not in stop_words]\n",
        "    bib_tokens = [stemmer.stem(token) for token in word_tokenize(bib) if token not in stop_words]\n",
        "    text_tokens = [stemmer.stem(token) for token in word_tokenize(text) if token not in stop_words]\n",
        "\n",
        "    # Combine tokens for title, author, bib, and text into a single list\n",
        "    doc_tokens = title_tokens + author_tokens + bib_tokens + text_tokens\n",
        "    preprocessed_documents.append(doc_tokens)\n",
        "    all_doc_tokens.extend(set(doc_tokens))  # Use set for faster lookup and remove duplicates\n",
        "\n",
        "# Calculate IDF for all terms\n",
        "term_counts = Counter(all_doc_tokens)\n",
        "document_count = len(preprocessed_documents)\n",
        "idf_values = {term: math.log((document_count - term_counts[term] + 0.5) / (term_counts[term] + 0.5) + 1) for term in term_counts}\n",
        "\n",
        "# Function to preprocess query\n",
        "def preprocess_query(query):\n",
        "    query_tokens = word_tokenize(query.lower())\n",
        "    filtered_query_tokens = [word for word in query_tokens if word not in stop_words]\n",
        "    return [stemmer.stem(word) for word in filtered_query_tokens]\n",
        "\n",
        "# Function to calculate BM25 score for a document\n",
        "def calculate_bm25_score(document, preprocessed_query, document_length, avg_document_length, k1, b):\n",
        "    score = 0.0\n",
        "    doc_term_freq = Counter(document)\n",
        "    for term in preprocessed_query:\n",
        "        if term not in document:\n",
        "            continue\n",
        "        term_frequency = doc_term_freq[term]\n",
        "        numerator = term_frequency * (k1 + 1)\n",
        "        denominator = term_frequency + k1 * (1 - b + b * (document_length / avg_document_length))\n",
        "        score += idf_values[term] * (numerator / denominator)\n",
        "    return score\n",
        "\n",
        "# Read queries from cran.qry.xml\n",
        "query_file = '/content/cran.qry.xml'\n",
        "queries_df = pd.read_xml(query_file)\n",
        "queries_df.index += 1  # Increment index by 1 to start from 1\n",
        "queries = list(zip(queries_df.index, queries_df['title']))\n",
        "\n",
        "# BM25 parameters\n",
        "avg_document_length = sum(len(doc) for doc in preprocessed_documents) / document_count\n",
        "k1 = 2.5\n",
        "b = 0.75\n",
        "\n",
        "# Write results to file\n",
        "with open(\"bm25_output.txt\", \"w\") as output_file:\n",
        "    for query_id, query_text in queries:\n",
        "        preprocessed_query = preprocess_query(query_text)\n",
        "        scores = []\n",
        "        for i, document in enumerate(preprocessed_documents, start=1):\n",
        "            score = calculate_bm25_score(document, preprocessed_query, len(document), avg_document_length, k1, b)\n",
        "            scores.append((i, score))\n",
        "        ranked_documents = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "        for rank, (doc_id, score) in enumerate(ranked_documents, start=1):\n",
        "            output_file.write(f\"{query_id} 0 {doc_id} {rank} {score} bm25\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E4Ps02WqRrN"
      },
      "source": [
        "# **QL** O/P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqCqMMstqVwS",
        "outputId": "b25aa6ca-18ad-4d67-8fe9-ef2b8ee95afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load XML data into a DataFrame\n",
        "df_docs = pd.read_xml('cran.all.1400.xml')\n",
        "\n",
        "# Preprocess text: tokenize, stem, remove stop words\n",
        "def preprocess_text(title, author, bib, text):\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    title_str = str(title) if pd.notnull(title) else ''\n",
        "    author_str = str(author) if pd.notnull(author) else ''\n",
        "    bib_str = str(bib) if pd.notnull(bib) else ''\n",
        "    text_str = str(text) if pd.notnull(text) else ''\n",
        "    all_text = ' '.join([title_str, author_str, bib_str, text_str])\n",
        "    tokens = word_tokenize(all_text.lower())\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Preprocess documents\n",
        "preprocessed_documents = [preprocess_text(row['title'], row['author'], row['bib'], row['text']) for _, row in df_docs.iterrows()]\n",
        "\n",
        "# Preprocess queries\n",
        "df_queries = pd.read_xml('cran.qry.xml')\n",
        "preprocessed_queries = {query_id: preprocess_text('', '', '', query_text) for query_id, query_text in zip(df_queries.index, df_queries['title'])}\n",
        "\n",
        "# Compute document language models (term frequencies) in batch\n",
        "doc_language_models = []\n",
        "for doc in preprocessed_documents:\n",
        "    term_freqs = Counter(doc.split())\n",
        "    total_terms = sum(term_freqs.values())\n",
        "    language_model = {term: freq / total_terms for term, freq in term_freqs.items()}\n",
        "    doc_language_models.append(language_model)\n",
        "\n",
        "# Additive Smoothing\n",
        "def calculate_smoothed_likelihood_score(query_language_model, doc_language_models, smoothing_param):\n",
        "    likelihood_scores = []\n",
        "    for doc_language_model in doc_language_models:\n",
        "        likelihood_score = 0.0\n",
        "        for term, query_term_prob in query_language_model.items():\n",
        "            doc_term_prob = doc_language_model.get(term, 0)  # Get term probability from document's language model\n",
        "            smoothed_term_prob = (1 - smoothing_param) * doc_term_prob + smoothing_param * query_term_prob\n",
        "            likelihood_score += query_term_prob * math.log(smoothed_term_prob + 1e-10)  # Smoothing for unseen terms\n",
        "        likelihood_scores.append(likelihood_score)\n",
        "    return likelihood_scores\n",
        "\n",
        "# Write to an output file\n",
        "output_file = \"query_likelihood_output.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for query_id, query_text in preprocessed_queries.items():\n",
        "        query_term_freqs = Counter(query_text.split())\n",
        "        query_total_terms = sum(query_term_freqs.values())\n",
        "        query_language_model = {term: freq / query_total_terms for term, freq in query_term_freqs.items()}\n",
        "        # Smoothing parameter\n",
        "        smoothing_param = 0.1\n",
        "        query_likelihood_scores = calculate_smoothed_likelihood_score(query_language_model, doc_language_models, smoothing_param)\n",
        "        results = sorted(enumerate(query_likelihood_scores, start=1), key=lambda x: x[1], reverse=True)\n",
        "        for rank, (doc_id, score) in enumerate(results[:100], start=1):\n",
        "            f.write(f\"{query_id} 0 {doc_id} {rank} {score:.4f} QL\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmR7gINN2uBK"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GEqK-o5zn_s",
        "outputId": "fba549d3-9d37-40f2-891d-cc05c3e15657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trec_eval'...\n",
            "remote: Enumerating objects: 1142, done.\u001b[K\n",
            "remote: Counting objects: 100% (291/291), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 1142 (delta 225), reused 237 (delta 188), pack-reused 851\u001b[K\n",
            "Receiving objects: 100% (1142/1142), 755.17 KiB | 10.49 MiB/s, done.\n",
            "Resolving deltas: 100% (769/769), done.\n",
            "make: Entering directory '/content/trec_eval'\n",
            "gcc -g -I.  -Wall -Wno-macro-redefined -DVERSIONID=\\\"10.0-rc2\\\"  -o trec_eval trec_eval.c formats.c meas_init.c meas_acc.c meas_avg.c meas_print_single.c meas_print_final.c gain_init.c get_qrels.c get_trec_results.c get_prefs.c get_qrels_prefs.c get_qrels_jg.c form_res_rels.c form_res_rels_jg.c form_prefs_counts.c utility_pool.c get_zscores.c convert_zscores.c measures.c  m_map.c m_P.c m_num_q.c m_num_ret.c m_num_rel.c m_num_rel_ret.c m_gm_map.c m_Rprec.c m_recip_rank.c m_bpref.c m_iprec_at_recall.c m_recall.c m_Rprec_mult.c m_utility.c m_11pt_avg.c m_ndcg.c m_ndcg_cut.c m_Rndcg.c m_ndcg_rel.c m_binG.c m_G.c m_rel_P.c m_success.c m_infap.c m_map_cut.c m_gm_bpref.c m_runid.c m_relstring.c m_set_P.c m_set_recall.c m_set_rel_P.c m_set_map.c m_set_F.c m_num_nonrel_judged_ret.c m_prefs_num_prefs_poss.c m_prefs_num_prefs_ful.c m_prefs_num_prefs_ful_ret.c m_prefs_simp.c m_prefs_pair.c m_prefs_avgjg.c m_prefs_avgjg_Rnonrel.c m_prefs_simp_ret.c m_prefs_pair_ret.c m_prefs_avgjg_ret.c m_prefs_avgjg_Rnonrel_ret.c m_prefs_simp_imp.c m_prefs_pair_imp.c m_prefs_avgjg_imp.c m_map_avgjg.c m_Rprec_mult_avgjg.c m_P_avgjg.c m_yaap.c m_rbp.c m_rbp_resid.c m_unjudged.c -lm\n",
            "make: Leaving directory '/content/trec_eval'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/usnistgov/trec_eval.git\n",
        "!make -C trec_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m9DPeGKCz4s",
        "outputId": "efe500e8-12b8-4865-a892-8191ed0a0846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results for VSM:\n",
            "map                   \tall\t0.2856\n",
            "P_5                   \tall\t0.3102\n",
            "ndcg                  \tall\t0.4920\n",
            "Evaluation results for BM25:\n",
            "map                   \tall\t0.3071\n",
            "P_5                   \tall\t0.3182\n",
            "ndcg                  \tall\t0.5646\n",
            "Evaluation results for QL:\n",
            "map                   \tall\t0.0633\n",
            "P_5                   \tall\t0.0750\n",
            "ndcg                  \tall\t0.1531\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Paths to relevance judgment file and search engine output files\n",
        "path_to_cranfield_qrel = \"/content/cranqrel.trec.txt\"\n",
        "path_to_engines = {\n",
        "    \"VSM\": \"/content/vsm_output.txt\",\n",
        "    \"BM25\": \"/content/bm25_output.txt\",\n",
        "    \"QL\": \"/content/query_likelihood_output.txt\"\n",
        "    }\n",
        "\n",
        "# Evaluation measures\n",
        "evaluation_measures = [\"map\", \"P.5\", \"ndcg\"]\n",
        "\n",
        "# Evaluate each search engine\n",
        "evaluation_results = {}\n",
        "for engine_name, output_file in path_to_engines.items():\n",
        "    print(f\"Evaluation results for {engine_name}:\")\n",
        "    !./trec_eval/trec_eval -m map -m P.5 -m ndcg {path_to_cranfield_qrel} {output_file}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8NBhrGc81d0L",
        "zDBw0oFR2YJ4"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOTBsnT38hgW60AY68MuOjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}