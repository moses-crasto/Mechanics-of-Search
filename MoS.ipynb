{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RmR7gINN2uBK",
        "8NBhrGc81d0L",
        "zDBw0oFR2YJ4",
        "jsiCEhSx7tQq"
      ],
      "authorship_tag": "ABX9TyNsSyXBQcDyQ1ILYp9WyUcv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moses-crasto/Mechanics-of-Search/blob/main/MoS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate**"
      ],
      "metadata": {
        "id": "RmR7gINN2uBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/usnistgov/trec_eval.git\n",
        "!make -C trec_eval"
      ],
      "metadata": {
        "id": "7GEqK-o5zn_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7a7d84-a0ec-429c-b505-f88486a1455e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trec_eval'...\n",
            "remote: Enumerating objects: 1142, done.\u001b[K\n",
            "remote: Counting objects: 100% (327/327), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 1142 (delta 260), reused 273 (delta 224), pack-reused 815\u001b[K\n",
            "Receiving objects: 100% (1142/1142), 763.21 KiB | 20.08 MiB/s, done.\n",
            "Resolving deltas: 100% (765/765), done.\n",
            "make: Entering directory '/content/trec_eval'\n",
            "gcc -g -I.  -Wall -Wno-macro-redefined -DVERSIONID=\\\"10.0-rc2\\\"  -o trec_eval trec_eval.c formats.c meas_init.c meas_acc.c meas_avg.c meas_print_single.c meas_print_final.c gain_init.c get_qrels.c get_trec_results.c get_prefs.c get_qrels_prefs.c get_qrels_jg.c form_res_rels.c form_res_rels_jg.c form_prefs_counts.c utility_pool.c get_zscores.c convert_zscores.c measures.c  m_map.c m_P.c m_num_q.c m_num_ret.c m_num_rel.c m_num_rel_ret.c m_gm_map.c m_Rprec.c m_recip_rank.c m_bpref.c m_iprec_at_recall.c m_recall.c m_Rprec_mult.c m_utility.c m_11pt_avg.c m_ndcg.c m_ndcg_cut.c m_Rndcg.c m_ndcg_rel.c m_binG.c m_G.c m_rel_P.c m_success.c m_infap.c m_map_cut.c m_gm_bpref.c m_runid.c m_relstring.c m_set_P.c m_set_recall.c m_set_rel_P.c m_set_map.c m_set_F.c m_num_nonrel_judged_ret.c m_prefs_num_prefs_poss.c m_prefs_num_prefs_ful.c m_prefs_num_prefs_ful_ret.c m_prefs_simp.c m_prefs_pair.c m_prefs_avgjg.c m_prefs_avgjg_Rnonrel.c m_prefs_simp_ret.c m_prefs_pair_ret.c m_prefs_avgjg_ret.c m_prefs_avgjg_Rnonrel_ret.c m_prefs_simp_imp.c m_prefs_pair_imp.c m_prefs_avgjg_imp.c m_map_avgjg.c m_Rprec_mult_avgjg.c m_P_avgjg.c m_yaap.c m_rbp.c m_rbp_resid.c m_unjudged.c -lm\n",
            "make: Leaving directory '/content/trec_eval'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Define paths to relevance judgment file and search engine output files\n",
        "path_to_cranfield_qrel = \"/content/cranqrel.trec.txt\"\n",
        "path_to_engines = {\n",
        "    \"VSM\": \"/content/vsm_output.txt\",\n",
        "    \"BM25\": \"/content/bm25_output.txt\",\n",
        "    \"QL\": \"/content/query_likelihood_output.txt\"\n",
        "    }\n",
        "\n",
        "# Define evaluation measures\n",
        "evaluation_measures = [\"map\", \"P.5\", \"ndcg\"]\n",
        "\n",
        "# Evaluate each search engine\n",
        "evaluation_results = {}\n",
        "for engine_name, output_file in path_to_engines.items():\n",
        "    print(f\"Evaluation results for {engine_name}:\")\n",
        "    !./trec_eval/trec_eval -m map -m P.5 -m ndcg {path_to_cranfield_qrel} {output_file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m9DPeGKCz4s",
        "outputId": "00322452-6952-42f3-ffc2-b9d540ec761b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results for VSM:\n",
            "map                   \tall\t0.0091\n",
            "P_5                   \tall\t0.0145\n",
            "ndcg                  \tall\t0.0395\n",
            "Evaluation results for BM25:\n",
            "map                   \tall\t0.0142\n",
            "P_5                   \tall\t0.0062\n",
            "ndcg                  \tall\t0.2176\n",
            "Evaluation results for QL:\n",
            "map                   \tall\t0.0074\n",
            "P_5                   \tall\t0.0132\n",
            "ndcg                  \tall\t0.0377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VSM O**/P"
      ],
      "metadata": {
        "id": "8NBhrGc81d0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define a function to parse the XML file\n",
        "def parse_xml_file(xml_file):\n",
        "    \"\"\"\n",
        "    Parse XML file to extract document text.\n",
        "\n",
        "    Args:\n",
        "    xml_file (str): Path to the XML file.\n",
        "\n",
        "    Returns:\n",
        "    list: List of document texts.\n",
        "    \"\"\"\n",
        "    docs = []\n",
        "    current_doc = \"\"\n",
        "    with open(xml_file, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.strip() == '<doc>':\n",
        "                current_doc = line\n",
        "            elif line.strip() == '</doc>':\n",
        "                current_doc += line\n",
        "                docs.append(current_doc)\n",
        "            elif current_doc:\n",
        "                current_doc += line\n",
        "    return docs\n",
        "\n",
        "# Load XML data into a DataFrame\n",
        "xml_file = '/content/cran.all.1400.xml'\n",
        "doc_elements = parse_xml_file(xml_file)\n",
        "df = pd.DataFrame(doc_elements, columns=['doc'])\n",
        "\n",
        "# Parse XML file to extract queries\n",
        "def parse_query_xml(xml_file):\n",
        "    \"\"\"\n",
        "    Parse XML file to extract queries.\n",
        "\n",
        "    Args:\n",
        "    xml_file (str): Path to the XML file containing queries.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing query IDs and corresponding texts.\n",
        "    \"\"\"\n",
        "    queries = {}\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for query in root.findall('top'):\n",
        "        query_number = query.find('num').text.strip().split()[-1]\n",
        "        query_text = query.find('title').text.strip()\n",
        "        queries[query_number] = query_text\n",
        "    return queries\n",
        "\n",
        "# Sample query\n",
        "queries = parse_query_xml('cran.qry.xml')\n",
        "\n",
        "# Step 1: Tokenize, preprocess, stem, and remove stop words from the text\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by tokenizing, stemming, and removing stop words.\n",
        "\n",
        "    Args:\n",
        "    text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "    str: Preprocessed text.\n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "preprocessed_documents = [preprocess_text(doc) for doc in df['doc']]\n",
        "\n",
        "# Adjust TF-IDF vectorizer parameters for better performance\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, min_df=0.008, max_features=2000, ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the preprocessed documents\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
        "\n",
        "output_file = \"vsm_output.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for query_id, query_text in queries.items():\n",
        "        preprocessed_query = preprocess_text(query_text)\n",
        "        query_vector = tfidf_vectorizer.transform([preprocessed_query])\n",
        "        cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
        "        results = [(df.index[i] + 1, cosine_similarities[0][i]) for i in range(len(df))]\n",
        "        results.sort(key=lambda x: x[1], reverse=True)\n",
        "        for rank, (docno, similarity) in enumerate(results[:100], start=1):\n",
        "            f.write(f\"{query_id} 0 {docno} {rank} {similarity} vsm\\n\")\n"
      ],
      "metadata": {
        "id": "Zp_dlOkFwNB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae98155-554d-40eb-8e57-f2e5afa31968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BM25** O/P"
      ],
      "metadata": {
        "id": "zDBw0oFR2YJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define a function to parse the XML file\n",
        "def parse_xml_file(xml_file):\n",
        "    docs = []\n",
        "    current_doc = \"\"\n",
        "    with open(xml_file, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.strip() == '<doc>':\n",
        "                current_doc = line\n",
        "            elif line.strip() == '</doc>':\n",
        "                current_doc += line\n",
        "                docs.append(current_doc)\n",
        "                current_doc = \"\"\n",
        "            elif current_doc:\n",
        "                current_doc += line\n",
        "    return docs\n",
        "\n",
        "# Load XML data into a DataFrame\n",
        "xml_file = '/content/cran.all.1400.xml'\n",
        "doc_elements = parse_xml_file(xml_file)\n",
        "df = pd.DataFrame(doc_elements, columns=['doc'])\n",
        "\n",
        "# Preprocess documents\n",
        "documents = []\n",
        "for doc in df['doc']:\n",
        "    root = ET.fromstring(doc)\n",
        "    text_element = root.find('text')\n",
        "    if text_element is not None and text_element.text is not None:\n",
        "        text = text_element.text.strip()\n",
        "        documents.append(text.split())\n",
        "\n",
        "# Define function to preprocess query\n",
        "def preprocess_query(query):\n",
        "    query_tokens = word_tokenize(query.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_query_tokens = [word for word in query_tokens if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(word) for word in filtered_query_tokens]\n",
        "\n",
        "# Function to calculate BM25 score for a document\n",
        "def calculate_bm25_score(document, preprocessed_query, document_count, avg_document_length, term_counts, k1, b):\n",
        "    score = 0.0\n",
        "    document_length = len(document)\n",
        "    for term in preprocessed_query:\n",
        "        if term not in document:\n",
        "            continue\n",
        "        document_with_term_count = term_counts[term]\n",
        "        idf = math.log((document_count - document_with_term_count + 0.5) / (document_with_term_count + 0.5))\n",
        "        term_frequency = document.count(term)\n",
        "        numerator = term_frequency * (k1 + 1)\n",
        "        denominator = term_frequency + k1 * (1 - b + b * (document_length / avg_document_length))\n",
        "        score += idf * (numerator / denominator)\n",
        "    return score\n",
        "\n",
        "# Read queries from cran.qry.xml\n",
        "def read_queries(query_file):\n",
        "    queries = []\n",
        "    current_query = \"\"\n",
        "    query_id = 0\n",
        "    with open(query_file, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.strip() == '<top>':\n",
        "                query_id += 1\n",
        "                current_query = \"\"\n",
        "            elif line.strip() == '</top>':\n",
        "                queries.append((query_id, current_query.strip()))\n",
        "            elif current_query:\n",
        "                current_query += line\n",
        "    return queries\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # BM25 parameters\n",
        "    document_count = len(documents)\n",
        "    avg_document_length = sum(len(doc) for doc in documents) / document_count\n",
        "    term_counts = Counter()\n",
        "    for document in documents:\n",
        "        term_counts.update(document)\n",
        "    k1 = 1.8\n",
        "    b = 0.8\n",
        "\n",
        "    # Read queries\n",
        "    query_file = '/content/cran.qry.xml'\n",
        "    queries = read_queries(query_file)\n",
        "\n",
        "    # Write results to file\n",
        "    with open(\"bm25_output.txt\", \"w\") as output_file:\n",
        "        for query_id, query_text in queries:\n",
        "            preprocessed_query = preprocess_query(query_text)\n",
        "            scores = []\n",
        "            for i, document in enumerate(documents, start=1):\n",
        "                score = calculate_bm25_score(document, preprocessed_query, document_count, avg_document_length, term_counts, k1, b)\n",
        "                scores.append((i, score))\n",
        "            ranked_documents = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "            for rank, (doc_id, score) in enumerate(ranked_documents, start=1):\n",
        "                output_file.write(f\"{query_id} 0 {doc_id} {rank} {score} bm25\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "V40gEndU1pWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525ec894-dc94-466b-e1c5-c01ae12b74d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QL** O/P"
      ],
      "metadata": {
        "id": "6E4Ps02WqRrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Parse XML file to extract document text\n",
        "def parse_xml_file(xml_file):\n",
        "    \"\"\"\n",
        "    Parse XML file to extract document text.\n",
        "\n",
        "    Args:\n",
        "    xml_file (str): Path to the XML file.\n",
        "\n",
        "    Returns:\n",
        "    list: List of document texts.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    current_doc = \"\"\n",
        "    with open(xml_file, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.strip() == '<doc>':\n",
        "                current_doc = line\n",
        "            elif line.strip() == '</doc>':\n",
        "                current_doc += line\n",
        "                documents.append(current_doc)\n",
        "            elif current_doc:\n",
        "                current_doc += line\n",
        "    return documents\n",
        "\n",
        "# Preprocess text: tokenize, stem, remove stop words\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by tokenizing, stemming, and removing stop words.\n",
        "\n",
        "    Args:\n",
        "    text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "    str: Preprocessed text.\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Load XML data into a DataFrame\n",
        "xml_file = 'cran.all.1400.xml'\n",
        "documents = parse_xml_file(xml_file)\n",
        "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
        "\n",
        "# Parse XML file to extract queries\n",
        "def parse_query_xml(xml_file):\n",
        "    \"\"\"\n",
        "    Parse XML file to extract queries.\n",
        "\n",
        "    Args:\n",
        "    xml_file (str): Path to the XML file containing queries.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing query IDs and corresponding texts.\n",
        "    \"\"\"\n",
        "    queries = {}\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for query in root.findall('top'):\n",
        "        query_number = query.find('num').text.strip().split()[-1]\n",
        "        query_text = query.find('title').text.strip()\n",
        "        queries[query_number] = query_text\n",
        "    return queries\n",
        "\n",
        "# Sample query\n",
        "queries = parse_query_xml('cran.qry.xml')\n",
        "\n",
        "# Preprocess queries\n",
        "preprocessed_queries = {query_id: preprocess_text(query_text) for query_id, query_text in queries.items()}\n",
        "\n",
        "# Compute document language models (term frequencies)\n",
        "doc_language_models = []\n",
        "for doc in preprocessed_documents:\n",
        "    term_freqs = Counter(doc.split())\n",
        "    total_terms = sum(term_freqs.values())\n",
        "    language_model = {term: freq / total_terms for term, freq in term_freqs.items()}\n",
        "    doc_language_models.append(language_model)\n",
        "\n",
        "# Advanced Smoothing Techniques\n",
        "def calculate_smoothed_likelihood_score(query_language_model, doc_language_model, smoothing_param):\n",
        "    likelihood_score = 0.0\n",
        "    for term, query_term_prob in query_language_model.items():\n",
        "        doc_term_prob = doc_language_model.get(term, 0)  # Get term probability from document's language model\n",
        "        smoothed_term_prob = (1 - smoothing_param) * doc_term_prob + smoothing_param * query_term_prob\n",
        "        likelihood_score += query_term_prob * math.log(smoothed_term_prob + 1e-10)  # Smoothing for unseen terms\n",
        "    return likelihood_score\n",
        "\n",
        "# Generate output file\n",
        "output_file = \"query_likelihood_output.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for query_id, query_text in preprocessed_queries.items():\n",
        "        query_term_freqs = Counter(query_text.split())\n",
        "        query_total_terms = sum(query_term_freqs.values())\n",
        "        query_language_model = {term: freq / query_total_terms for term, freq in query_term_freqs.items()}\n",
        "        query_likelihood_scores = []\n",
        "        for doc_language_model in doc_language_models:\n",
        "            # Adjust smoothing parameter for better performance\n",
        "            smoothing_param = 0.1\n",
        "            likelihood_score = calculate_smoothed_likelihood_score(query_language_model, doc_language_model, smoothing_param)\n",
        "            query_likelihood_scores.append(likelihood_score)\n",
        "        results = sorted(enumerate(query_likelihood_scores, start=1), key=lambda x: x[1], reverse=True)\n",
        "        for rank, (doc_id, score) in enumerate(results[:100], start=1):\n",
        "            f.write(f\"{query_id} 0 {doc_id} {rank} {score:.4f} QL\\n\")\n"
      ],
      "metadata": {
        "id": "aqCqMMstqVwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c50c922-e23e-480a-df4e-f3712c0abc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}